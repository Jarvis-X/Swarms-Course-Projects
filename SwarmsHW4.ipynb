{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD1+MZSj3cH/olF5Hy6xTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jarvis-X/Swarms-Course-Projects/blob/main/SwarmsHW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Value iteration with gym visualization\n",
        "\n",
        "* First cell - libraries\n",
        "* Second cell - imports\n",
        "* Third cell - Same as HW3, the helper functions that decides the input -output relations for the Gridworld, the definitions of the states and actions, `γ=1.0`, number of robots and environment size setup.\n",
        "  - ### NEW: `disturb` function that randomly (also time-invariant) shifts a robot stepping on the tile to one of the five directions: UP, DOWN, LEFT, RIGHT, and STAY\n",
        "* Forth cell - Same as HW3, finding the future reward of a state\n",
        "  - ### NEW: disturbance is introduced\n",
        "* ### Fifth cell - `GridMultiagentEnv` class that inherits `gym.Env` class, which I used in conjunction with pygame for visualization. For better training performance, I decided not to visualize the training process.\n",
        "* ### Sixth cell - extract the best policy using the value function on a random initial configuration of the robots.\n",
        "  - ## HIGHLIGHT: It is possible to have suboptimal actions if we blindly find the *first* action corresponding to the maximum value function. Therefore, when extracting the actions, I further discouraged repetitive motions of the robots (such as a deadlock in-and-out motion of two robots around one target) and encouraged the robots if their intended next move is towards the target. Moreover, I shuffled the sequence of the actions related to the maximum value function to avoid more rare dead lock. \n",
        "* Sixth cell: deprecated visualization, for debugging only now.\n",
        "* Seventh cell: saving the value functions to local storage for further insoection."
      ],
      "metadata": {
        "id": "GhyLfUTri0Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame\n",
        "!pip install gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uGkxmegXs4u",
        "outputId": "9bd27db3-ad78-48da-fc65-e8a2bb5a2ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfEcTSyWNVmI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gym import spaces\n",
        "import gym\n",
        "\n",
        "import os\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "import pygame\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from gym.envs.registration import register"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialization\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "# define a timeout\n",
        "timeout = 500\n",
        "\n",
        "# number of robots\n",
        "num_robots = 2\n",
        "\n",
        "# reward of each move\n",
        "r = -1\n",
        "\n",
        "# reward of collision\n",
        "r_n_MAX = -1E3\n",
        "\n",
        "# reward of reaching goal\n",
        "r_p_MAX = 0\n",
        "\n",
        "# random seed\n",
        "np.random.seed(int(time.time_ns()%2**24))\n",
        "\n",
        "# Grid exporation\n",
        "UP = int(0); DOWN = int(1); RIGHT = int(2); LEFT = int(3); \n",
        "STAY = int(-1) # special case\n",
        "actions_single_robot = [UP, DOWN, RIGHT, LEFT]\n",
        "default_total_possible_actions = len(actions_single_robot)**num_robots\n",
        "\n",
        "env_size = int(6)\n",
        "rows = env_size\n",
        "cols = env_size\n",
        "\n",
        "# parameters\n",
        "theta = 0.001\n",
        "gamma = 1.0\n",
        "num_states = (rows*cols)**num_robots\n",
        "\n",
        "# state of the explorer enumerated from 1 to row x cols -2\n",
        "def init_single_robot_random_state(rows: int, cols: int) -> int:\n",
        "    state = int(np.random.choice(range(rows*cols - 2)) + 1)\n",
        "    return state\n",
        "\n",
        "# initialize states\n",
        "states = [init_single_robot_random_state(rows, cols) for _ in range(num_robots)]\n",
        "\n",
        "# if a robot is at a state, how an action changes its state\n",
        "def single_robot_state_action_to_newstate(s: int, action: int, rows: int, cols: int) -> int:\n",
        "    if action == UP:\n",
        "        # print(\"UP\")\n",
        "        if s in range(0, cols):\n",
        "            sprime = s\n",
        "        else:\n",
        "            sprime = s - cols\n",
        "    elif action == DOWN:\n",
        "        # print(\"DOWN\")\n",
        "        if s in range((rows-1)*cols, rows*cols):\n",
        "            sprime = s\n",
        "        else:\n",
        "            sprime = s + cols\n",
        "    elif action == LEFT:\n",
        "        # print(\"LEFT\")\n",
        "        if s in range(0, cols*rows, cols):\n",
        "            sprime = s\n",
        "        else:\n",
        "            sprime = s - 1\n",
        "    elif action == RIGHT:\n",
        "        # print(\"RIGHT\")\n",
        "        if s in range(cols-1, cols*rows, cols):\n",
        "            sprime = s\n",
        "        else:\n",
        "            sprime = s + 1\n",
        "    elif action == STAY:\n",
        "        sprime = s\n",
        "    else:\n",
        "        raise Exception(\"wrong action!\")\n",
        "        # print(\"STAY\")\n",
        "        \n",
        "    # print(s)\n",
        "    return int(sprime)\n",
        "\n",
        "# unknown dynamics of the environment (time-invariant)\n",
        "def disturb(rows: int, cols: int):\n",
        "    disturbance = {}\n",
        "    for i in range(rows*cols):\n",
        "        # TODO: enable this\n",
        "        disturbance[int(i)] = np.random.choice(range(-1, len(actions_single_robot)))\n",
        "        # disturbance[int(i)] = int(-1)\n",
        "    return disturbance\n",
        "\n",
        "disturbance = disturb(rows, cols)\n",
        "\n",
        "# helper function that implements the philosophy above\n",
        "def from_state_to_index(rows: int, cols: int, num_robot: int, states: list) -> int:\n",
        "    ind_s = int(0)\n",
        "    layer_thiccness = int(rows*cols)\n",
        "    for depth in range(len(states)):\n",
        "        ind_s += int(states[depth]*layer_thiccness**(num_robot - depth - 1))\n",
        "    return ind_s\n",
        "\n",
        "# and of course, its inverse\n",
        "def from_index_to_state(rows: int, cols: int, num_robot: int, ind_s: int) -> list:\n",
        "    states = []\n",
        "    remnant = ind_s\n",
        "    layer_thiccness = int(rows*cols)\n",
        "    for i in range(num_robot):\n",
        "        s = remnant % layer_thiccness\n",
        "        remnant //= layer_thiccness\n",
        "        states.insert(0, s)\n",
        "    return states\n",
        "\n",
        "# similarly, we need to apply the philosophy on the actions\n",
        "def from_action_to_index(num_robot: int, actions: list) -> int:\n",
        "    ind_a = int(0)\n",
        "    layer_thiccness = int(4)\n",
        "    for depth in range(len(actions)):\n",
        "        ind_a += int(actions[depth]*layer_thiccness**(num_robot - depth - 1))\n",
        "    return ind_a\n",
        "\n",
        "# and of course, its inverse\n",
        "def from_index_to_action(num_robot: int, ind_a: int) -> list:\n",
        "    actions = []\n",
        "    remnant = ind_a\n",
        "    layer_thiccness = int(4)\n",
        "    for i in range(num_robot):\n",
        "        a = remnant % layer_thiccness\n",
        "        remnant //= layer_thiccness\n",
        "        actions.insert(0, a)\n",
        "    return actions\n",
        "\n",
        "# a helper function that extracts the position of a single robot\n",
        "def from_state_to_position(rows, cols, state):\n",
        "    row = state // cols\n",
        "    col = state % cols\n",
        "    return np.array([col, row], dtype=int)"
      ],
      "metadata": {
        "id": "JOc8g6ZD_LEw"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value iteration algorithm\n",
        "def cal_future_reward(states, actions, rows, cols, V, gamma, disturbance) -> float:\n",
        "    future_reward = 0\n",
        "    new_states = []\n",
        "    action_index = 0\n",
        "    for single_robot_state in states:\n",
        "        sprime = single_robot_state_action_to_newstate(single_robot_state, actions[action_index], rows, cols)\n",
        "        disturbance_action = disturbance[sprime]\n",
        "        sprime = single_robot_state_action_to_newstate(sprime, disturbance_action, rows, cols)\n",
        "        if (sprime in new_states) and (sprime != int(0)) and (sprime != int(rows*cols-1)):\n",
        "            future_reward += r_n_MAX + gamma*V[sprime]\n",
        "            sprime = single_robot_state\n",
        "        elif (sprime == int(0)) or (sprime == int(rows*cols-1)):\n",
        "            future_reward += r_p_MAX*((sprime == int(0)) + (sprime == int(rows*cols-1))) + gamma*V[sprime]\n",
        "        else:\n",
        "            future_reward += r + gamma*V[sprime]\n",
        "\n",
        "        new_states.append(sprime)\n",
        "        action_index += 1\n",
        "    return future_reward\n",
        "\n",
        "time_begin = time.time()\n",
        "\n",
        "# value function\n",
        "V_iterative = np.zeros(num_states)\n",
        "\n",
        "while True:\n",
        "    if time.time() - time_begin >= timeout*10:\n",
        "        # print(evolving_policy.pi_matrix)\n",
        "        print(\"Time out!!\")\n",
        "        break\n",
        "    \n",
        "    delta = 0\n",
        "    \n",
        "    for multi_robot_state in range(num_states):\n",
        "        # get the current value function\n",
        "        v = V_iterative[multi_robot_state]\n",
        "\n",
        "        # obtain the maximum future reward\n",
        "        separate_states = from_index_to_state(rows, cols, num_robots, multi_robot_state)\n",
        "        Vs = -1E20\n",
        "        for multi_robot_action in range(default_total_possible_actions):\n",
        "            separate_actions = from_index_to_action(num_robots, multi_robot_action)\n",
        "            # now we have the state and the action of each robot, get the \n",
        "            # new state of each robot and calculate the reward\n",
        "            future_reward = cal_future_reward(separate_states, separate_actions, rows, cols, V_iterative, gamma, disturbance)\n",
        "            if future_reward > Vs:\n",
        "                Vs = future_reward\n",
        "        V_iterative[multi_robot_state] = Vs\n",
        "\n",
        "        delta = max(delta, abs(v - Vs))\n",
        "\n",
        "    if delta < theta:\n",
        "        print(\"Evaluated!!\")\n",
        "        break\n",
        "        # print(V_iterative.reshape((rows, cols, -1)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG_eWiFFfgTn",
        "outputId": "9ff094cf-8691-426b-cd6a-d5ce5dc84bcf"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the custom grid world class from gym's official documentation\n",
        "# ref-> https://www.gymlibrary.dev/content/environment_creation/\n",
        "# changes made: number of agents (1 -> n)\n",
        "#               number of targets (1 -> 2)\n",
        "class GridMultiagentEnv(gym.Env):\n",
        "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 2}\n",
        "    def __init__(self, disturbance, render_mode=None, size=3, num_agents=2):\n",
        "        self.size = size  # The size of the square grid\n",
        "        self.window_size = 512  # The size of the PyGame window\n",
        "        self.num_agents = num_agents\n",
        "\n",
        "        self._states = int(0)\n",
        "        # Target position is fixed at the upper-left and lower-right corner\n",
        "        self._target_states = np.array([0, cols*rows-1], dtype=int)\n",
        "\n",
        "        \"\"\"\n",
        "        Based on the position in the gridworld, we want to add a disturbance to\n",
        "        emmulate the unknown dynamics of the environment\n",
        "        \"\"\"\n",
        "        self.disturbance = disturbance\n",
        "        \n",
        "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
        "        self.render_mode = render_mode\n",
        "\n",
        "        \"\"\"\n",
        "        If human-rendering is used, `self.window` will be a reference\n",
        "        to the window that we draw to. `self.clock` will be a clock that is used\n",
        "        to ensure that the environment is rendered at the correct framerate in\n",
        "        human-mode. They will remain `None` until human-mode is used for the\n",
        "        first time.\n",
        "        \"\"\"\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "\n",
        "    def _get_obs(self):\n",
        "        print(\"states from internal obs\", self._states)\n",
        "        return self._target_states.tolist() + [self._states]\n",
        "\n",
        "    def _get_info(self):\n",
        "        return None\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # Choose the agent's states uniformly at random\n",
        "        new_states = np.random.choice(rows*cols, size=num_robots, replace=False).tolist()    \n",
        "        self._states = from_state_to_index(self.size, self.size, self.num_agents, new_states)\n",
        "\n",
        "        observation = self._get_obs()\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "\n",
        "        return observation\n",
        "\n",
        "    def step(self, action):\n",
        "        # Map the action (element of {0,1, ..., 4**num_robots-1}) to the \n",
        "        # directions the robots walk in, affected by the unknown environmental \n",
        "        # dynamics\n",
        "        states = from_index_to_state(self.size, self.size, self.num_agents, self._states)\n",
        "        actions = from_index_to_action(self.num_agents, action)\n",
        "        new_states = []\n",
        "        action_index = 0\n",
        "        reward = 0\n",
        "\n",
        "        # An episode is done iff all agents have reached the target\n",
        "        terminated = True\n",
        "        for single_robot_state in states:\n",
        "            sprime = single_robot_state_action_to_newstate(single_robot_state, actions[action_index], self.size, self.size)\n",
        "            disturbance_action = self.disturbance[sprime]\n",
        "            sprime = single_robot_state_action_to_newstate(sprime, disturbance_action, self.size, self.size)\n",
        "            print(\"new single state\", sprime)\n",
        "            if (sprime in new_states) and not np.any(sprime == self._target_states):\n",
        "                sprime = single_robot_state\n",
        "                reward += r_n_MAX\n",
        "            if not np.any(sprime == self._target_states):\n",
        "                terminated = False\n",
        "                reward += r\n",
        " \n",
        "            new_states.append(sprime)\n",
        "            action_index += 1\n",
        "\n",
        "        print(new_states)\n",
        "        self._states = from_state_to_index(self.size, self.size, self.num_agents, new_states)\n",
        "        \n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "\n",
        "        return observation, reward, terminated, info\n",
        "\n",
        "    def render(self):\n",
        "        ret = self._render_frame()\n",
        "        if self.render_mode == \"rgb_array\":\n",
        "            return ret\n",
        "\n",
        "    def _render_frame(self):\n",
        "        if self.window is None and self.render_mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
        "        if self.clock is None and self.render_mode == \"human\":\n",
        "            self.clock = pygame.time.Clock()\n",
        "\n",
        "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
        "        canvas.fill((84, 92, 27))\n",
        "        pix_square_size = (\n",
        "            self.window_size / self.size\n",
        "        )  # The size of a single grid square in pixels\n",
        "\n",
        "        # First we draw the targets\n",
        "        for target in self._target_states:\n",
        "            target_pos = from_state_to_position(self.size, self.size, target)\n",
        "            pygame.draw.rect(\n",
        "                canvas,\n",
        "                (204, 174, 192),\n",
        "                pygame.Rect(\n",
        "                    pix_square_size * target_pos,\n",
        "                    (pix_square_size, pix_square_size),\n",
        "                ),\n",
        "            )\n",
        "\n",
        "        # Now we draw the agents\n",
        "        states = from_index_to_state(self.size, self.size, self.num_agents, self._states)\n",
        "        for state in states:\n",
        "            pygame.draw.circle(\n",
        "                canvas,\n",
        "                (176, 177, 149),\n",
        "                (from_state_to_position(self.size, self.size, state) + 0.5 ) * pix_square_size,\n",
        "                pix_square_size / 3,\n",
        "            )\n",
        "\n",
        "        # Finally, add some gridlines\n",
        "        for x in range(self.size + 1):\n",
        "            pygame.draw.line(\n",
        "                canvas,\n",
        "                0,\n",
        "                (0, pix_square_size * x),\n",
        "                (self.window_size, pix_square_size * x),\n",
        "                width=3,\n",
        "            )\n",
        "            pygame.draw.line(\n",
        "                canvas,\n",
        "                0,\n",
        "                (pix_square_size * x, 0),\n",
        "                (pix_square_size * x, self.window_size),\n",
        "                width=3,\n",
        "            )\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            # The following line copies our drawings from `canvas` to the visible window\n",
        "            # which is not working on Colab\n",
        "            # self.window.blit(canvas, canvas.get_rect())\n",
        "            # pygame.event.pump()\n",
        "            # pygame.display.update()\n",
        "\n",
        "            # use the following instead\n",
        "            output.clear(wait=True)\n",
        "            cv2_imshow(np.transpose(\n",
        "                    np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
        "            # The following line will automatically add a delay to keep the framerate stable.\n",
        "            self.clock.tick(self.metadata[\"render_fps\"])\n",
        "        else:  # rgb_array\n",
        "            return np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
        "            )\n",
        "\n",
        "    def close(self):\n",
        "        if self.window is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()\n"
      ],
      "metadata": {
        "id": "AYVFhDJzirNj"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = GridMultiagentEnv(render_mode=\"human\", num_agents=num_robots, size=env_size, disturbance=disturbance)\n",
        "obs = env.reset()\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    state_index = obs[2]\n",
        "    ss = from_index_to_state(rows, cols, num_robots, state_index) \n",
        "\n",
        "    # extract the policy\n",
        "    possible_action_values = []\n",
        "\n",
        "    for multi_robot_action in range(default_total_possible_actions):\n",
        "        separate_actions = from_index_to_action(num_robots, multi_robot_action)\n",
        "        new_ss = []\n",
        "        action_index = 0\n",
        "\n",
        "        for s in ss:\n",
        "            sp = single_robot_state_action_to_newstate(s, separate_actions[action_index], rows, cols)\n",
        "            disturbance_action = disturbance[sp]\n",
        "            sp = single_robot_state_action_to_newstate(sp, disturbance_action, rows, cols)\n",
        "            if (sp in ss) and (sp != int(0)) and (sp != int(rows*cols-1)):\n",
        "                sp = s\n",
        "            new_ss.append(sp)\n",
        "            action_index += 1\n",
        "        \n",
        "        action_discourage = 0.1*r*np.sum([new_ss[i] in ss and not (int(new_ss[i]) in [int(0), int(rows*cols-1)]) for i in range(num_robots)])\n",
        "        action_encourage = -10*r*np.sum([int(new_ss[i]) in [int(0), int(rows*cols-1)] for i in range(num_robots)])\n",
        "        new_state_index = from_state_to_index(rows, cols, num_robots, new_ss)\n",
        "        possible_action_values.append(V_iterative[new_state_index] + action_discourage + action_encourage)\n",
        "\n",
        "    # action_to_take = np.argmax(possible_action_values)\n",
        "    # In case we are stuck at some wierd dead loop\n",
        "    action_to_take = np.random.choice(np.argwhere(possible_action_values == np.max(possible_action_values)).flatten())\n",
        "    print(\"action to take\", action_to_take)\n",
        "    # time.sleep(5)\n",
        "    obs, reward, done, info = env.step(action_to_take)\n",
        "    print(\"returned obs\", from_index_to_state(rows, cols, num_robots, obs[2]))\n",
        "\n"
      ],
      "metadata": {
        "id": "SPFmrwxpJB9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "37cf6780-3cb7-4f6e-b8b1-1d21b7229aa4"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7F8AE3BAF6A0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "returned obs [0, 15, 0, 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot = True\n",
        "if plot:\n",
        "    ################################################################################\n",
        "    # visualization\n",
        "    ###############\n",
        "    from matplotlib import colors\n",
        "    # # create discrete colormap\n",
        "    cmap = colors.ListedColormap(['red', 'blue'])\n",
        "    bounds = [-10,10,20]\n",
        "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    figi, axi = plt.subplots(figsize=(12, 12))\n",
        "    imi = axi.imshow(V_iterative.reshape((rows*cols, rows*cols))[:, 0].reshape(rows, cols))\n",
        "\n",
        "    # draw gridlines\n",
        "    # ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=2)\n",
        "\n",
        "    # col_labels = [int(100/nx)*i for i in range(nx+1)]\n",
        "    # row_labels = [int(100/ny)*i for i in range(ny+1)]\n",
        "\n",
        "    # plt.xticks([1]+col_labels, [1]+col_labels)\n",
        "    # plt.yticks(row_labels, [label/25 for label in row_labels])\n",
        "\n",
        "    axi.set_xticks(np.arange(cols));\n",
        "    axi.set_yticks(np.arange(rows));\n",
        "    axi.set_xticklabels(np.arange(1, cols+1, 1))\n",
        "    axi.set_yticklabels(np.arange(1, rows+1, 1))\n",
        "\n",
        "    plt.colorbar(imi)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "HYf_M-TZipUY",
        "outputId": "3e609817-79d0-4c0a-88c3-9f04dc6fa9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('Env4x4and4RobotsValueFunction.pickle', 'wb') as handle:\n",
        "    pickle.dump(V_iterative, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "HdNj41tjk5xF"
      },
      "execution_count": 192,
      "outputs": []
    }
  ]
}